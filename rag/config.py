"""
RAGä¸ªäººçŸ¥è¯†åº“é…ç½®æ¨¡å—
å‚è€ƒBERTé¡¹ç›®çš„ç®€åŒ–é…ç½®æ–¹å¼ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œå®šä¹‰ï¼Œè¿è¡Œæ—¶ä¸éœ€è¦æ‰‹åŠ¨ä¼ å‚
"""

import os
import logging
from typing import List
from pydantic import BaseModel, Field, field_validator
from pathlib import Path
from datetime import datetime


class EmbeddingConfig(BaseModel):
    """æ–‡æœ¬åµŒå…¥é…ç½®"""
    
    model_name: str = Field(default="BAAI/bge-small-zh-v1.5", description="åµŒå…¥æ¨¡å‹åç§°")
    device: str = Field(default="mps", description="è®¡ç®—è®¾å¤‡")
    max_length: int = Field(default=512, description="æœ€å¤§æ–‡æœ¬é•¿åº¦")
    batch_size: int = Field(default=32, description="æ‰¹å¤„ç†å¤§å°")
    cache_dir: str = Field(default="/Users/liuqianli/.cache/huggingface/hub", description="æ¨¡å‹ç¼“å­˜ç›®å½•")
     
    class Config:
        extra = "forbid"


class LLMConfig(BaseModel):
    """å¤§è¯­è¨€æ¨¡å‹é…ç½®"""
    
    api_key: str = Field(default="", description="é€šä¹‰ç™¾ç‚¼APIå¯†é’¥")
    model_name: str = Field(default="qwen-plus", description="æ¨¡å‹åç§°")
    temperature: float = Field(default=0.7, description="é‡‡æ ·æ¸©åº¦")
    top_p: float = Field(default=0.9, description="æ ¸é‡‡æ ·æ¦‚ç‡")
    max_tokens: int = Field(default=2048, description="æœ€å¤§ç”Ÿæˆtokenæ•°")
    timeout: int = Field(default=60, description="è¯·æ±‚è¶…æ—¶æ—¶é—´")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    class Config:
        extra = "forbid"


class VectorStoreConfig(BaseModel):
    """å‘é‡å­˜å‚¨é…ç½®"""

    # é€šç”¨é…ç½®
    backend: str = Field(default="chromadb", description="å‘é‡æ•°æ®åº“åç«¯: chromadb, postgresql")
    collection_name: str = Field(default="knowledge_base", description="é›†åˆåç§°")
    top_k: int = Field(default=5, description="æ£€ç´¢è¿”å›æ•°é‡")
    score_threshold: float = Field(default=0.3, description="ç›¸ä¼¼åº¦é˜ˆå€¼")

    # ChromaDBé…ç½®
    persist_directory: str = Field(default="data/vectorstore", description="ChromaDBæ•°æ®ç›®å½•")

    class Config:
        extra = "forbid"


class TextSplitterConfig(BaseModel):
    """æ–‡æœ¬åˆ†å‰²é…ç½®"""
    
    chunk_size: int = Field(default=500, description="æ–‡æœ¬å—å¤§å°")
    chunk_overlap: int = Field(default=50, description="æ–‡æœ¬å—é‡å å¤§å°")
    separators: List[str] = Field(
        default=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""], 
        description="åˆ†å‰²ç¬¦åˆ—è¡¨"
    )
    
    @field_validator("chunk_overlap")
    @classmethod
    def validate_overlap(cls, v, info):
        chunk_size = info.data.get("chunk_size", 500)
        if v >= chunk_size:
            raise ValueError("chunk_overlapå¿…é¡»å°äºchunk_size")
        return v
    
    class Config:
        extra = "forbid"


class TokenizerConfig(BaseModel):
    """åˆ†è¯å™¨é…ç½®"""
    
    tokenizer_type: str = Field(default="jieba", description="åˆ†è¯å™¨ç±»å‹")
    remove_stop_words: bool = Field(default=True, description="æ˜¯å¦ç§»é™¤åœç”¨è¯")
    
    class Config:
        extra = "forbid"


class PathConfig(BaseModel):
    """è·¯å¾„é…ç½®"""
    
    data_dir: str = Field(default="data", description="æ•°æ®æ ¹ç›®å½•")
    documents_dir: str = Field(default="data/documents", description="æ–‡æ¡£ç›®å½•")
    vectorstore_dir: str = Field(default="data/vectorstore", description="å‘é‡å­˜å‚¨ç›®å½•")
    log_dir: str = Field(default="/Users/liuqianli/work/python/deepai/logs/rag", description="æ—¥å¿—ç›®å½•")
    
    class Config:
        extra = "forbid"


class LoggingConfig(BaseModel):
    """æ—¥å¿—é…ç½®"""

    log_level: str = Field(default="INFO", description="æ—¥å¿—çº§åˆ«")
    log_format: str = Field(
        default="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        description="æ—¥å¿—æ ¼å¼"
    )

    class Config:
        extra = "forbid"


class RedisConfig(BaseModel):
    """Redisé…ç½®"""

    host: str = Field(default="localhost", description="Redisä¸»æœºåœ°å€")
    port: int = Field(default=6379, description="Redisç«¯å£")
    db: int = Field(default=0, description="Redisæ•°æ®åº“ç¼–å·")
    password: str = Field(default="", description="Rediså¯†ç ")
    decode_responses: bool = Field(default=True, description="æ˜¯å¦è§£ç å“åº”")
    socket_timeout: int = Field(default=5, description="è¿æ¥è¶…æ—¶æ—¶é—´")
    session_expire: int = Field(default=3600, description="ä¼šè¯è¿‡æœŸæ—¶é—´(ç§’)")
    key_prefix: str = Field(default="rag:session:", description="ä¼šè¯é”®å‰ç¼€")
    context_window_key: str = Field(default="rag:context:", description="ä¸Šä¸‹æ–‡çª—å£é”®å‰ç¼€")
    max_context_length: int = Field(default=4000, description="æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦(tokens)")

    class Config:
        extra = "forbid"


class ElasticsearchConfig(BaseModel):
    """Elasticsearché…ç½®"""

    host: str = Field(default="localhost", description="ESä¸»æœºåœ°å€")
    port: int = Field(default=9200, description="ESç«¯å£")
    username: str = Field(default="", description="ESç”¨æˆ·å")
    password: str = Field(default="", description="ESå¯†ç ")
    use_ssl: bool = Field(default=False, description="æ˜¯å¦ä½¿ç”¨SSL")
    verify_certs: bool = Field(default=False, description="æ˜¯å¦éªŒè¯è¯ä¹¦")
    timeout: int = Field(default=30, description="è¿æ¥è¶…æ—¶æ—¶é—´")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
    index_name: str = Field(default="rag_documents", description="æ–‡æ¡£ç´¢å¼•åç§°")

    class Config:
        extra = "forbid"


class MySQLConfig(BaseModel):
    """MySQLé…ç½®"""

    host: str = Field(default="localhost", description="MySQLä¸»æœºåœ°å€")
    port: int = Field(default=3306, description="MySQLç«¯å£")
    username: str = Field(default="root", description="MySQLç”¨æˆ·å")
    password: str = Field(default="root", description="MySQLå¯†ç ")
    database: str = Field(default="rag_system", description="æ•°æ®åº“åç§°")
    charset: str = Field(default="utf8mb4", description="å­—ç¬¦é›†")
    autocommit: bool = Field(default=True, description="æ˜¯å¦è‡ªåŠ¨æäº¤")
    pool_size: int = Field(default=10, description="è¿æ¥æ± å¤§å°")
    max_overflow: int = Field(default=20, description="è¿æ¥æ± æœ€å¤§æº¢å‡º")
    pool_timeout: int = Field(default=30, description="è¿æ¥æ± è¶…æ—¶æ—¶é—´")

    class Config:
        extra = "forbid"


class PostgreSQLConfig(BaseModel):
    """PostgreSQLå‘é‡æ•°æ®åº“é…ç½®"""

    host: str = Field(default="localhost", description="PostgreSQLä¸»æœºåœ°å€")
    port: int = Field(default=5432, description="PostgreSQLç«¯å£")
    username: str = Field(default="postgres", description="PostgreSQLç”¨æˆ·å")
    password: str = Field(default="postgres", description="PostgreSQLå¯†ç ")
    database: str = Field(default="rag_vectordb", description="å‘é‡æ•°æ®åº“åç§°")
    table_name: str = Field(default="documents", description="æ–‡æ¡£è¡¨åç§°")
    vector_dimension: int = Field(default=512, description="å‘é‡ç»´åº¦")
    pool_size: int = Field(default=10, description="è¿æ¥æ± å¤§å°")
    max_overflow: int = Field(default=20, description="è¿æ¥æ± æœ€å¤§æº¢å‡º")
    pool_timeout: int = Field(default=30, description="è¿æ¥æ± è¶…æ—¶æ—¶é—´")

    class Config:
        extra = "forbid"


class RerankerConfig(BaseModel):
    """é‡æ’åºå™¨é…ç½®"""

    # åŒç¼–ç å™¨é…ç½®
    bi_encoder_model: str = Field(default="BAAI/bge-reranker-base", description="åŒç¼–ç å™¨æ¨¡å‹åç§°")
    bi_encoder_enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨åŒç¼–ç å™¨")
    bi_encoder_top_k: int = Field(default=20, description="åŒç¼–ç å™¨ç­›é€‰çš„å€™é€‰æ•°é‡")

    # äº¤å‰ç¼–ç å™¨é…ç½®
    cross_encoder_model: str = Field(default="BAAI/bge-reranker-v2-m3", description="äº¤å‰ç¼–ç å™¨æ¨¡å‹åç§°")
    cross_encoder_enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨äº¤å‰ç¼–ç å™¨")
    cross_encoder_top_k: int = Field(default=10, description="äº¤å‰ç¼–ç å™¨æœ€ç»ˆè¿”å›æ•°é‡")

    # é€šç”¨é…ç½®
    device: str = Field(default="auto", description="è®¡ç®—è®¾å¤‡")
    batch_size: int = Field(default=16, description="æ‰¹å¤„ç†å¤§å°")
    cache_dir: str = Field(default="/Users/liuqianli/.cache/huggingface/hub", description="æ¨¡å‹ç¼“å­˜ç›®å½•")

    # åˆ†æ•°èåˆé…ç½®
    fusion_method: str = Field(default="weighted", description="åˆ†æ•°èåˆæ–¹æ³•: weighted, rrf, max")
    bi_encoder_weight: float = Field(default=0.3, description="åŒç¼–ç å™¨æƒé‡")
    cross_encoder_weight: float = Field(default=0.7, description="äº¤å‰ç¼–ç å™¨æƒé‡")
    original_weight: float = Field(default=0.2, description="åŸå§‹æ£€ç´¢åˆ†æ•°æƒé‡")

    class Config:
        extra = "forbid"



def get_device() -> str:
    """è‡ªåŠ¨æ£€æµ‹è®¾å¤‡"""
    try:
        import torch
        if defaultConfig.embedding.device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        else:
            return defaultConfig.embedding.device
    except ImportError:
        return "cpu"


def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path(defaultConfig.path.log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)

    log_filename = f"rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    log_filepath = log_dir / log_filename

    logging.basicConfig(
        level=getattr(logging, defaultConfig.logging.log_level),
        format=defaultConfig.logging.log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filepath, encoding="utf-8"),
        ],
    )

    logger = logging.getLogger("RAG")
    logger.setLevel(getattr(logging, defaultConfig.logging.log_level))
    return logger


def create_directories():
    """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
    directories = [
        defaultConfig.path.data_dir,
        defaultConfig.path.documents_dir,
        defaultConfig.path.vectorstore_dir,
        defaultConfig.path.log_dir,
        defaultConfig.embedding.cache_dir,
    ]

    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")


def load_env_config():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
    if api_key := os.getenv("DASHSCOPE_API_KEY"):
        defaultConfig.llm.api_key = api_key

    if device := os.getenv("RAG_DEVICE"):
        defaultConfig.embedding.device = device


def print_config():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("=" * 50)
    print("RAGä¸ªäººçŸ¥è¯†åº“é…ç½®ä¿¡æ¯")
    print("=" * 50)

    print(f"\nğŸ¤– LLMé…ç½®:")
    print(f"  æ¨¡å‹: {defaultConfig.llm.model_name}")
    print(f"  æ¸©åº¦: {defaultConfig.llm.temperature}")
    print(f"  æœ€å¤§tokens: {defaultConfig.llm.max_tokens}")
    print(f"  APIå¯†é’¥: {'å·²è®¾ç½®' if defaultConfig.llm.api_key else 'æœªè®¾ç½®'}")

    print(f"\nğŸ“Š åµŒå…¥é…ç½®:")
    print(f"  æ¨¡å‹: {defaultConfig.embedding.model_name}")
    print(f"  è®¾å¤‡: {get_device()}")
    print(f"  æœ€å¤§é•¿åº¦: {defaultConfig.embedding.max_length}")
    print(f"  æ‰¹æ¬¡å¤§å°: {defaultConfig.embedding.batch_size}")

    print(f"\nğŸ—‚ï¸ å‘é‡å­˜å‚¨é…ç½®:")
    print(f"  å­˜å‚¨ç›®å½•: {defaultConfig.vector_store.persist_directory}")
    print(f"  é›†åˆåç§°: {defaultConfig.vector_store.collection_name}")
    print(f"  æ£€ç´¢æ•°é‡: {defaultConfig.vector_store.top_k}")
    print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {defaultConfig.vector_store.score_threshold}")

    print(f"\nğŸ“ æ–‡æœ¬åˆ†å‰²é…ç½®:")
    print(f"  å—å¤§å°: {defaultConfig.text_splitter.chunk_size}")
    print(f"  é‡å å¤§å°: {defaultConfig.text_splitter.chunk_overlap}")

    print(f"\nğŸ“ è·¯å¾„é…ç½®:")
    print(f"  æ•°æ®ç›®å½•: {defaultConfig.path.data_dir}")
    print(f"  æ–‡æ¡£ç›®å½•: {defaultConfig.path.documents_dir}")
    print(f"  æ—¥å¿—ç›®å½•: {defaultConfig.path.log_dir}")

    print("=" * 50)


class Config(BaseModel):
    """æ€»é…ç½®ç±»"""
    vector_store: VectorStoreConfig = Field(default_factory=VectorStoreConfig)
    embedding: EmbeddingConfig = Field(default_factory=EmbeddingConfig)
    llm: LLMConfig = Field(default_factory=LLMConfig)
    text_splitter: TextSplitterConfig = Field(default_factory=TextSplitterConfig)
    tokenizer: TokenizerConfig = Field(default_factory=TokenizerConfig)
    path: PathConfig = Field(default_factory=PathConfig)
    logging: LoggingConfig = Field(default_factory=LoggingConfig)
    redis: RedisConfig = Field(default_factory=RedisConfig)
    elasticsearch: ElasticsearchConfig = Field(default_factory=ElasticsearchConfig)
    mysql: MySQLConfig = Field(default_factory=MySQLConfig)
    postgresql: PostgreSQLConfig = Field(default_factory=PostgreSQLConfig)
    reranker: RerankerConfig = Field(default_factory=RerankerConfig)

# é»˜è®¤é…ç½®å®ä¾‹
defaultConfig = Config()


if __name__ == "__main__":
    load_env_config()
    print_config()
    
    device = get_device()
    print(f"\næ£€æµ‹åˆ°çš„è®¾å¤‡: {device}")
    
    logger = setup_logging()
    logger.info("é…ç½®æ¨¡å—æµ‹è¯•æˆåŠŸï¼")
