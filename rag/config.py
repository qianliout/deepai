"""
RAGä¸ªäººçŸ¥è¯†åº“é…ç½®æ¨¡å—
å‚è€ƒBERTé¡¹ç›®çš„ç®€åŒ–é…ç½®æ–¹å¼ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œå®šä¹‰ï¼Œè¿è¡Œæ—¶ä¸éœ€è¦æ‰‹åŠ¨ä¼ å‚
"""

import os
import logging
from typing import List
from pydantic import BaseModel, Field, field_validator
from pathlib import Path
from datetime import datetime


class EmbeddingConfig(BaseModel):
    """æ–‡æœ¬åµŒå…¥é…ç½®"""
    
    model_name: str = Field(default="BAAI/bge-small-zh-v1.5", description="åµŒå…¥æ¨¡å‹åç§°")
    device: str = Field(default="mps", description="è®¡ç®—è®¾å¤‡")
    max_length: int = Field(default=512, description="æœ€å¤§æ–‡æœ¬é•¿åº¦")
    batch_size: int = Field(default=32, description="æ‰¹å¤„ç†å¤§å°")
    cache_dir: str = Field(default="/Users/liuqianli/.cache/huggingface/hub", description="æ¨¡å‹ç¼“å­˜ç›®å½•")
    
    class Config:
        extra = "forbid"


class LLMConfig(BaseModel):
    """å¤§è¯­è¨€æ¨¡å‹é…ç½®"""
    
    api_key: str = Field(default="", description="é€šä¹‰ç™¾ç‚¼APIå¯†é’¥")
    model_name: str = Field(default="qwen-plus", description="æ¨¡å‹åç§°")
    temperature: float = Field(default=0.7, description="é‡‡æ ·æ¸©åº¦")
    top_p: float = Field(default=0.9, description="æ ¸é‡‡æ ·æ¦‚ç‡")
    max_tokens: int = Field(default=2048, description="æœ€å¤§ç”Ÿæˆtokenæ•°")
    timeout: int = Field(default=60, description="è¯·æ±‚è¶…æ—¶æ—¶é—´")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    class Config:
        extra = "forbid"


class VectorStoreConfig(BaseModel):
    """å‘é‡å­˜å‚¨é…ç½®"""
    
    persist_directory: str = Field(default="data/vectorstore", description="ChromaDBæ•°æ®ç›®å½•")
    collection_name: str = Field(default="knowledge_base", description="é›†åˆåç§°")
    top_k: int = Field(default=5, description="æ£€ç´¢è¿”å›æ•°é‡")
    score_threshold: float = Field(default=0.7, description="ç›¸ä¼¼åº¦é˜ˆå€¼")
    
    class Config:
        extra = "forbid"


class TextSplitterConfig(BaseModel):
    """æ–‡æœ¬åˆ†å‰²é…ç½®"""
    
    chunk_size: int = Field(default=500, description="æ–‡æœ¬å—å¤§å°")
    chunk_overlap: int = Field(default=50, description="æ–‡æœ¬å—é‡å å¤§å°")
    separators: List[str] = Field(
        default=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""], 
        description="åˆ†å‰²ç¬¦åˆ—è¡¨"
    )
    
    @field_validator("chunk_overlap")
    @classmethod
    def validate_overlap(cls, v, info):
        chunk_size = info.data.get("chunk_size", 500)
        if v >= chunk_size:
            raise ValueError("chunk_overlapå¿…é¡»å°äºchunk_size")
        return v
    
    class Config:
        extra = "forbid"


class TokenizerConfig(BaseModel):
    """åˆ†è¯å™¨é…ç½®"""
    
    tokenizer_type: str = Field(default="jieba", description="åˆ†è¯å™¨ç±»å‹")
    remove_stop_words: bool = Field(default=True, description="æ˜¯å¦ç§»é™¤åœç”¨è¯")
    
    class Config:
        extra = "forbid"


class PathConfig(BaseModel):
    """è·¯å¾„é…ç½®"""
    
    data_dir: str = Field(default="data", description="æ•°æ®æ ¹ç›®å½•")
    documents_dir: str = Field(default="data/documents", description="æ–‡æ¡£ç›®å½•")
    vectorstore_dir: str = Field(default="data/vectorstore", description="å‘é‡å­˜å‚¨ç›®å½•")
    log_dir: str = Field(default="logs", description="æ—¥å¿—ç›®å½•")
    
    class Config:
        extra = "forbid"


class LoggingConfig(BaseModel):
    """æ—¥å¿—é…ç½®"""
    
    log_level: str = Field(default="INFO", description="æ—¥å¿—çº§åˆ«")
    log_format: str = Field(
        default="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        description="æ—¥å¿—æ ¼å¼"
    )
    
    class Config:
        extra = "forbid"


# å…¨å±€é…ç½®å®ä¾‹ - å‚è€ƒBERTé¡¹ç›®çš„æ–¹å¼
EMBEDDING_CONFIG = EmbeddingConfig()
LLM_CONFIG = LLMConfig()
VECTORSTORE_CONFIG = VectorStoreConfig()
TEXT_SPLITTER_CONFIG = TextSplitterConfig()
TOKENIZER_CONFIG = TokenizerConfig()
PATH_CONFIG = PathConfig()
LOGGING_CONFIG = LoggingConfig()


def get_device() -> str:
    """è‡ªåŠ¨æ£€æµ‹è®¾å¤‡"""
    try:
        import torch
        if EMBEDDING_CONFIG.device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        else:
            return EMBEDDING_CONFIG.device
    except ImportError:
        return "cpu"


def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path(PATH_CONFIG.log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)
    
    log_filename = f"rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    log_filepath = log_dir / log_filename
    
    logging.basicConfig(
        level=getattr(logging, LOGGING_CONFIG.log_level),
        format=LOGGING_CONFIG.log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filepath, encoding="utf-8"),
        ],
    )
    
    logger = logging.getLogger("RAG")
    logger.setLevel(getattr(logging, LOGGING_CONFIG.log_level))
    return logger


def create_directories():
    """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
    directories = [
        PATH_CONFIG.data_dir,
        PATH_CONFIG.documents_dir,
        PATH_CONFIG.vectorstore_dir,
        PATH_CONFIG.log_dir,
        EMBEDDING_CONFIG.cache_dir,
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")


def load_env_config():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
    if api_key := os.getenv("DASHSCOPE_API_KEY"):
        LLM_CONFIG.api_key = api_key
    
    if device := os.getenv("RAG_DEVICE"):
        EMBEDDING_CONFIG.device = device


def print_config():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("=" * 50)
    print("RAGä¸ªäººçŸ¥è¯†åº“é…ç½®ä¿¡æ¯")
    print("=" * 50)
    
    print(f"\nğŸ¤– LLMé…ç½®:")
    print(f"  æ¨¡å‹: {LLM_CONFIG.model_name}")
    print(f"  æ¸©åº¦: {LLM_CONFIG.temperature}")
    print(f"  æœ€å¤§tokens: {LLM_CONFIG.max_tokens}")
    print(f"  APIå¯†é’¥: {'å·²è®¾ç½®' if LLM_CONFIG.api_key else 'æœªè®¾ç½®'}")
    
    print(f"\nğŸ“Š åµŒå…¥é…ç½®:")
    print(f"  æ¨¡å‹: {EMBEDDING_CONFIG.model_name}")
    print(f"  è®¾å¤‡: {get_device()}")
    print(f"  æœ€å¤§é•¿åº¦: {EMBEDDING_CONFIG.max_length}")
    print(f"  æ‰¹æ¬¡å¤§å°: {EMBEDDING_CONFIG.batch_size}")
    
    print(f"\nğŸ—‚ï¸ å‘é‡å­˜å‚¨é…ç½®:")
    print(f"  å­˜å‚¨ç›®å½•: {VECTORSTORE_CONFIG.persist_directory}")
    print(f"  é›†åˆåç§°: {VECTORSTORE_CONFIG.collection_name}")
    print(f"  æ£€ç´¢æ•°é‡: {VECTORSTORE_CONFIG.top_k}")
    print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {VECTORSTORE_CONFIG.score_threshold}")
    
    print(f"\nğŸ“ æ–‡æœ¬åˆ†å‰²é…ç½®:")
    print(f"  å—å¤§å°: {TEXT_SPLITTER_CONFIG.chunk_size}")
    print(f"  é‡å å¤§å°: {TEXT_SPLITTER_CONFIG.chunk_overlap}")
    
    print(f"\nğŸ“ è·¯å¾„é…ç½®:")
    print(f"  æ•°æ®ç›®å½•: {PATH_CONFIG.data_dir}")
    print(f"  æ–‡æ¡£ç›®å½•: {PATH_CONFIG.documents_dir}")
    print(f"  æ—¥å¿—ç›®å½•: {PATH_CONFIG.log_dir}")
    
    print("=" * 50)



if __name__ == "__main__":
    load_env_config()
    print_config()
    
    device = get_device()
    print(f"\næ£€æµ‹åˆ°çš„è®¾å¤‡: {device}")
    
    logger = setup_logging()
    logger.info("é…ç½®æ¨¡å—æµ‹è¯•æˆåŠŸï¼")
