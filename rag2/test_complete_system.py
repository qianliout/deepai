#!/usr/bin/env python3
"""
RAG2é¡¹ç›®å®Œæ•´ç³»ç»Ÿæµ‹è¯•
æµ‹è¯•ä»æ–‡æ¡£å¤„ç†åˆ°RAGæŸ¥è¯¢çš„å®Œæ•´æµç¨‹
"""

import asyncio
import sys
import os
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.config import get_config
from utils.logger import get_logger, LogContext
from core.document_processor import DocumentProcessor
from core.rag_pipeline import get_rag_pipeline
from retrieval.semantic_retriever import SemanticRetriever
from retrieval.base_retriever import get_retriever_manager
from storage.postgresql_manager import PostgreSQLManager
from storage.redis_manager import RedisManager
from storage.mysql_manager import MySQLManager

logger = get_logger("test_complete_system")

class SystemTester:
    """ç³»ç»Ÿæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.test_results = {}
    
    async def test_database_connections(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        logger.info("=== æµ‹è¯•æ•°æ®åº“è¿æ¥ ===")
        
        results = {}
        
        # PostgreSQL
        try:
            pg_manager = PostgreSQLManager()
            await pg_manager.initialize()
            results["PostgreSQL"] = await pg_manager.health_check()
            await pg_manager.close()
        except Exception as e:
            logger.error(f"PostgreSQLæµ‹è¯•å¤±è´¥: {str(e)}")
            results["PostgreSQL"] = False
        
        # Redis
        try:
            redis_manager = RedisManager()
            await redis_manager.initialize()
            results["Redis"] = await redis_manager.health_check()
            await redis_manager.close()
        except Exception as e:
            logger.error(f"Redisæµ‹è¯•å¤±è´¥: {str(e)}")
            results["Redis"] = False
        
        # MySQL
        try:
            mysql_manager = MySQLManager()
            await mysql_manager.initialize()
            results["MySQL"] = await mysql_manager.health_check()
            await mysql_manager.close()
        except Exception as e:
            logger.error(f"MySQLæµ‹è¯•å¤±è´¥: {str(e)}")
            results["MySQL"] = False
        
        self.test_results["databases"] = results
        
        success_count = sum(1 for success in results.values() if success)
        logger.info(f"æ•°æ®åº“è¿æ¥æµ‹è¯•: {success_count}/{len(results)} æˆåŠŸ")
        
        return success_count > 0
    
    async def test_model_loading(self):
        """æµ‹è¯•æ¨¡å‹åŠ è½½"""
        logger.info("=== æµ‹è¯•æ¨¡å‹åŠ è½½ ===")
        
        results = {}
        
        # åµŒå…¥æ¨¡å‹
        try:
            from models.embeddings import get_embedding_manager
            embedding_manager = get_embedding_manager()
            
            # æµ‹è¯•ç¼–ç 
            test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
            embedding = embedding_manager.encode_text(test_text)
            
            results["embedding"] = len(embedding) > 0
            logger.info(f"åµŒå…¥æ¨¡å‹æµ‹è¯•: {'âœ… æˆåŠŸ' if results['embedding'] else 'âŒ å¤±è´¥'}")
            
        except Exception as e:
            logger.error(f"åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
            results["embedding"] = False
        
        # é‡æ’åºæ¨¡å‹
        try:
            from models.rerank_models import get_rerank_manager
            rerank_manager = get_rerank_manager()
            
            # æµ‹è¯•é‡æ’åº
            test_query = "æµ‹è¯•æŸ¥è¯¢"
            test_docs = ["ç›¸å…³æ–‡æ¡£", "ä¸ç›¸å…³æ–‡æ¡£"]
            rerank_results = rerank_manager.rerank_documents(test_query, test_docs)
            
            results["reranker"] = len(rerank_results) > 0
            logger.info(f"é‡æ’åºæ¨¡å‹æµ‹è¯•: {'âœ… æˆåŠŸ' if results['reranker'] else 'âŒ å¤±è´¥'}")
            
        except Exception as e:
            logger.error(f"é‡æ’åºæ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
            results["reranker"] = False
        
        # LLMå®¢æˆ·ç«¯
        try:
            from models.llm_client import get_llm_client
            llm_client = await get_llm_client()
            
            results["llm"] = await llm_client.health_check()
            logger.info(f"LLMå®¢æˆ·ç«¯æµ‹è¯•: {'âœ… æˆåŠŸ' if results['llm'] else 'âŒ å¤±è´¥'}")
            
        except Exception as e:
            logger.error(f"LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
            results["llm"] = False
        
        self.test_results["models"] = results
        
        success_count = sum(1 for success in results.values() if success)
        logger.info(f"æ¨¡å‹åŠ è½½æµ‹è¯•: {success_count}/{len(results)} æˆåŠŸ")
        
        return success_count > 0
    
    async def test_document_processing(self):
        """æµ‹è¯•æ–‡æ¡£å¤„ç†"""
        logger.info("=== æµ‹è¯•æ–‡æ¡£å¤„ç† ===")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
            test_doc_path = Path("data/test_document.txt")
            test_doc_path.parent.mkdir(parents=True, exist_ok=True)
            
            test_content = """
AIOpså®‰å…¨æœ€ä½³å®è·µ

1. å®¹å™¨å®‰å…¨
å®¹å™¨å®‰å…¨æ˜¯ç°ä»£AIOpsç¯å¢ƒä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚ä»¥ä¸‹æ˜¯ç¡®ä¿å®¹å™¨å®‰å…¨çš„åŸºæœ¬åŸåˆ™ï¼š

1.1 é•œåƒå®‰å…¨
- ä½¿ç”¨å®˜æ–¹æˆ–å¯ä¿¡çš„åŸºç¡€é•œåƒ
- å®šæœŸæ‰«æé•œåƒæ¼æ´ï¼Œå»ºè®®ä½¿ç”¨Trivyã€Clairæˆ–Snykç­‰å·¥å…·
- å®æ–½é•œåƒç­¾åéªŒè¯æœºåˆ¶

1.2 è¿è¡Œæ—¶å®‰å…¨
- ä»¥érootç”¨æˆ·è¿è¡Œå®¹å™¨
- ä½¿ç”¨åªè¯»æ–‡ä»¶ç³»ç»Ÿ
- é™åˆ¶å®¹å™¨çš„ç³»ç»Ÿè°ƒç”¨æƒé™

2. æ¼æ´ç®¡ç†
å»ºç«‹è‡ªåŠ¨åŒ–æ¼æ´æ‰«ææµç¨‹ï¼Œé›†æˆCI/CDç®¡é“ä¸­çš„å®‰å…¨æ£€æŸ¥ã€‚

CVE-2024-1234æ˜¯ä¸€ä¸ªé«˜å±æ¼æ´ï¼Œå½±å“nginx:latesté•œåƒã€‚
å»ºè®®ç«‹å³æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ä»¥ä¿®å¤æ­¤æ¼æ´ã€‚
"""
            
            with open(test_doc_path, 'w', encoding='utf-8') as f:
                f.write(test_content)
            
            # æµ‹è¯•æ–‡æ¡£å¤„ç†
            processor = DocumentProcessor()
            result = await processor.process_document(str(test_doc_path))
            
            # éªŒè¯ç»“æœ
            document = result["document"]
            chunks = result["chunks"]
            
            success = (
                len(document["content"]) > 0 and
                len(chunks) > 0 and
                all("embedding" in chunk for chunk in chunks)
            )
            
            logger.info(f"æ–‡æ¡£å¤„ç†æµ‹è¯•: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
            logger.info(f"  - æ–‡æ¡£é•¿åº¦: {len(document['content'])}")
            logger.info(f"  - åˆ†å—æ•°é‡: {len(chunks)}")
            logger.info(f"  - åµŒå…¥ç»´åº¦: {len(chunks[0]['embedding']) if chunks else 0}")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            test_doc_path.unlink()
            
            self.test_results["document_processing"] = success
            return success
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£å¤„ç†æµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results["document_processing"] = False
            return False
    
    async def test_retrieval_system(self):
        """æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ"""
        logger.info("=== æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ ===")
        
        try:
            # åˆ›å»ºè¯­ä¹‰æ£€ç´¢å™¨
            semantic_retriever = SemanticRetriever()
            
            # æ³¨å†Œæ£€ç´¢å™¨
            retriever_manager = get_retriever_manager()
            retriever_manager.register_retriever(semantic_retriever, is_default=True)
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            test_documents = [{
                "document": {
                    "id": "test-doc-1",
                    "title": "AIOpså®‰å…¨æŒ‡å—",
                    "content": "è¿™æ˜¯ä¸€ä¸ªå…³äºAIOpså®‰å…¨çš„æµ‹è¯•æ–‡æ¡£ã€‚åŒ…å«å®¹å™¨å®‰å…¨ã€æ¼æ´ç®¡ç†ç­‰å†…å®¹ã€‚",
                    "source": "test",
                    "document_type": "txt",
                    "metadata": {"test": True}
                },
                "chunks": [{
                    "id": "test-chunk-1",
                    "document_id": "test-doc-1",
                    "chunk_index": 0,
                    "content": "AIOpså®‰å…¨æ˜¯ç°ä»£è¿ç»´çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬å®¹å™¨å®‰å…¨ã€æ¼æ´ç®¡ç†ã€è®¿é—®æ§åˆ¶ç­‰æ–¹é¢ã€‚",
                    "token_count": 25,
                    "chunk_metadata": {"test": True}
                }]
            }]
            
            # æ·»åŠ æ–‡æ¡£åˆ°æ£€ç´¢å™¨
            add_success = await semantic_retriever.add_documents(test_documents)
            
            if add_success:
                # æµ‹è¯•æ£€ç´¢
                await asyncio.sleep(1)  # ç­‰å¾…ç´¢å¼•æ›´æ–°
                
                results = await semantic_retriever.retrieve("AIOpså®‰å…¨", top_k=5)
                
                success = len(results) > 0
                logger.info(f"æ£€ç´¢ç³»ç»Ÿæµ‹è¯•: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
                logger.info(f"  - æ£€ç´¢ç»“æœæ•°: {len(results)}")
                
                if results:
                    logger.info(f"  - æœ€é«˜ç›¸ä¼¼åº¦: {results[0].get('similarity', 0):.4f}")
            else:
                success = False
                logger.error("æ–‡æ¡£æ·»åŠ å¤±è´¥")
            
            self.test_results["retrieval"] = success
            return success
            
        except Exception as e:
            logger.error(f"æ£€ç´¢ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results["retrieval"] = False
            return False
    
    async def test_rag_pipeline(self):
        """æµ‹è¯•RAGç®¡é“"""
        logger.info("=== æµ‹è¯•RAGç®¡é“ ===")
        
        try:
            rag_pipeline = await get_rag_pipeline()
            
            # æµ‹è¯•æŸ¥è¯¢
            test_queries = [
                "ä»€ä¹ˆæ˜¯AIOpså®‰å…¨ï¼Ÿ",
                "å¦‚ä½•ç¡®ä¿å®¹å™¨å®‰å…¨ï¼Ÿ",
                "CVE-2024-1234æ¼æ´çš„å½±å“æ˜¯ä»€ä¹ˆï¼Ÿ"
            ]
            
            success_count = 0
            
            for query in test_queries:
                try:
                    result = await rag_pipeline.query(query)
                    
                    if result and result.get("response"):
                        success_count += 1
                        logger.info(f"æŸ¥è¯¢æˆåŠŸ: {query[:20]}... -> {result['response'][:50]}...")
                    else:
                        logger.warning(f"æŸ¥è¯¢æ— å“åº”: {query}")
                        
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢å¤±è´¥: {query}, é”™è¯¯: {str(e)}")
            
            success = success_count > 0
            logger.info(f"RAGç®¡é“æµ‹è¯•: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
            logger.info(f"  - æˆåŠŸæŸ¥è¯¢: {success_count}/{len(test_queries)}")
            
            self.test_results["rag_pipeline"] = success
            return success
            
        except Exception as e:
            logger.error(f"RAGç®¡é“æµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results["rag_pipeline"] = False
            return False
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹RAG2å®Œæ•´ç³»ç»Ÿæµ‹è¯•")
        
        start_time = time.time()
        
        # è¿è¡Œæµ‹è¯•
        tests = [
            ("æ•°æ®åº“è¿æ¥", self.test_database_connections()),
            ("æ¨¡å‹åŠ è½½", self.test_model_loading()),
            ("æ–‡æ¡£å¤„ç†", self.test_document_processing()),
            ("æ£€ç´¢ç³»ç»Ÿ", self.test_retrieval_system()),
            ("RAGç®¡é“", self.test_rag_pipeline())
        ]
        
        results = []
        for test_name, test_coro in tests:
            logger.info(f"\n--- å¼€å§‹æµ‹è¯•: {test_name} ---")
            try:
                result = await test_coro
                results.append((test_name, result))
            except Exception as e:
                logger.error(f"æµ‹è¯• {test_name} å¼‚å¸¸: {str(e)}")
                results.append((test_name, False))
        
        # æ±‡æ€»ç»“æœ
        end_time = time.time()
        total_time = end_time - start_time
        
        success_count = sum(1 for _, success in results if success)
        total_count = len(results)
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        logger.info("=" * 60)
        
        for test_name, success in results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            logger.info(f"{test_name:20} : {status}")
        
        logger.info("-" * 60)
        logger.info(f"æ€»ä½“ç»“æœ: {success_count}/{total_count} æµ‹è¯•é€šè¿‡")
        logger.info(f"æµ‹è¯•è€—æ—¶: {total_time:.2f} ç§’")
        
        if success_count == total_count:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
            return 0
        else:
            logger.warning(f"âš ï¸  æœ‰ {total_count - success_count} é¡¹æµ‹è¯•å¤±è´¥")
            return 1

async def main():
    """ä¸»å‡½æ•°"""
    tester = SystemTester()
    return await tester.run_all_tests()

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        sys.exit(1)
