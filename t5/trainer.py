"""
T5è®­ç»ƒå™¨æ¨¡å—
è´Ÿè´£æ¨¡å‹è®­ç»ƒã€éªŒè¯å’Œä¿å­˜
é‡ç‚¹å…³æ³¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®æµè½¬å’Œæ€§èƒ½ç›‘æ§
"""

import torch
import torch.nn as nn
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup
from torch.utils.data import DataLoader
import os
import json
from typing import Dict, List, Optional, Tuple
import logging
from tqdm import tqdm
from datetime import datetime
import numpy as np

from config import T5_CONFIG, TRAINING_CONFIG, get_device, create_directories
from model import T5ForConditionalGeneration
from data_loader import create_data_loader

logger = logging.getLogger("T5")


class T5Trainer:
    """
    T5è®­ç»ƒå™¨
    
    è´Ÿè´£å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼š
    1. æ¨¡å‹åˆå§‹åŒ–
    2. æ•°æ®åŠ è½½
    3. ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨è®¾ç½®
    4. è®­ç»ƒå¾ªç¯
    5. éªŒè¯å’Œä¿å­˜
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        logger.info("åˆå§‹åŒ–T5è®­ç»ƒå™¨...")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        create_directories()
        
        # è®¾å¤‡è®¾ç½®
        self.device = get_device()
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        logger.info("åˆå§‹åŒ–T5æ¨¡å‹...")
        self.model = T5ForConditionalGeneration()
        self.model.to(self.device)
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.global_step = 0
        self.best_loss = float('inf')
        self.training_history = []
        
        # ç›®å½•è®¾ç½®
        self.checkpoints_dir = TRAINING_CONFIG.pretrain_checkpoints_dir
        self.best_model_dir = TRAINING_CONFIG.pretrain_best_dir
        self.final_model_dir = TRAINING_CONFIG.pretrain_final_dir
        
        logger.info("T5è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def setup_data_loaders(self) -> Tuple[DataLoader, DataLoader]:
        """
        è®¾ç½®æ•°æ®åŠ è½½å™¨
        
        Returns:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        """
        logger.info("è®¾ç½®æ•°æ®åŠ è½½å™¨...")
        
        # è®­ç»ƒæ•°æ®åŠ è½½å™¨
        train_loader = create_data_loader(
            dataset_name=TRAINING_CONFIG.dataset_name,
            split="train",
            batch_size=TRAINING_CONFIG.batch_size,
            max_samples=TRAINING_CONFIG.max_samples,
            shuffle=True
        )
        
        # éªŒè¯æ•°æ®åŠ è½½å™¨
        val_loader = create_data_loader(
            dataset_name=TRAINING_CONFIG.dataset_name,
            split="validation",
            batch_size=TRAINING_CONFIG.batch_size,
            max_samples=TRAINING_CONFIG.max_samples // 5 if TRAINING_CONFIG.max_samples else None,
            shuffle=False
        )
        
        logger.info(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}, éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        return train_loader, val_loader
    
    def setup_optimizer_and_scheduler(self, train_loader: DataLoader) -> Tuple[AdamW, object]:
        """
        è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            
        Returns:
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        """
        logger.info("è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨...")
        
        # ä¼˜åŒ–å™¨
        optimizer = AdamW(
            self.model.parameters(),
            lr=TRAINING_CONFIG.learning_rate,
            betas=(TRAINING_CONFIG.adam_beta1, TRAINING_CONFIG.adam_beta2),
            eps=TRAINING_CONFIG.adam_epsilon,
            weight_decay=TRAINING_CONFIG.weight_decay
        )
        
        # è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°
        total_steps = len(train_loader) * TRAINING_CONFIG.num_epochs
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=TRAINING_CONFIG.warmup_steps,
            num_training_steps=total_steps
        )
        
        logger.info(f"æ€»è®­ç»ƒæ­¥æ•°: {total_steps}, é¢„çƒ­æ­¥æ•°: {TRAINING_CONFIG.warmup_steps}")
        return optimizer, scheduler
    
    def train_epoch(
        self, 
        train_loader: DataLoader, 
        optimizer: AdamW, 
        scheduler: object
    ) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            
        Returns:
            epoch_metrics: epochæŒ‡æ ‡
        """
        self.model.train()
        total_loss = 0.0
        num_batches = len(train_loader)
        
        # è¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f"Epoch {self.current_epoch + 1}/{TRAINING_CONFIG.num_epochs}")
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            batch = {k: v.to(self.device) for k, v in batch.items()}
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(
                input_ids=batch["input_ids"],  # (batch_size, encoder_seq_len)
                attention_mask=batch["attention_mask"],  # (batch_size, encoder_seq_len)
                decoder_input_ids=batch["decoder_input_ids"],  # (batch_size, decoder_seq_len)
                decoder_attention_mask=batch["decoder_attention_mask"],  # (batch_size, decoder_seq_len)
                labels=batch["labels"]  # (batch_size, decoder_seq_len)
            )
            
            loss = outputs["loss"]
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), TRAINING_CONFIG.max_grad_norm)
            
            # ä¼˜åŒ–å™¨æ­¥è¿›
            optimizer.step()
            scheduler.step()
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            total_loss += loss.item()
            self.global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = scheduler.get_last_lr()[0]
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}',
                'lr': f'{current_lr:.2e}'
            })
            
            # å®šæœŸæ—¥å¿—è®°å½•
            if self.global_step % TRAINING_CONFIG.logging_steps == 0:
                logger.info(
                    f"Step {self.global_step}: loss={loss.item():.4f}, "
                    f"avg_loss={total_loss / (batch_idx + 1):.4f}, lr={current_lr:.2e}"
                )
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if self.global_step % TRAINING_CONFIG.save_steps == 0:
                self.save_checkpoint(optimizer, scheduler)
        
        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_loss = total_loss / num_batches
        
        return {
            "train_loss": avg_loss,
            "learning_rate": scheduler.get_last_lr()[0]
        }
    
    def validate(self, val_loader: DataLoader) -> Dict[str, float]:
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            
        Returns:
            val_metrics: éªŒè¯æŒ‡æ ‡
        """
        self.model.eval()
        total_loss = 0.0
        num_batches = len(val_loader)
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc="Validation")
            
            for batch in pbar:
                # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
                batch = {k: v.to(self.device) for k, v in batch.items()}
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(
                    input_ids=batch["input_ids"],
                    attention_mask=batch["attention_mask"],
                    decoder_input_ids=batch["decoder_input_ids"],
                    decoder_attention_mask=batch["decoder_attention_mask"],
                    labels=batch["labels"]
                )
                
                loss = outputs["loss"]
                total_loss += loss.item()
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({'val_loss': f'{loss.item():.4f}'})
        
        avg_loss = total_loss / num_batches
        
        return {
            "val_loss": avg_loss
        }
    
    def save_checkpoint(self, optimizer: AdamW, scheduler: object):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹
        
        Args:
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        """
        checkpoint_path = os.path.join(
            self.checkpoints_dir, 
            f"checkpoint_epoch_{self.current_epoch}_step_{self.global_step}.pt"
        )
        
        checkpoint = {
            "epoch": self.current_epoch,
            "global_step": self.global_step,
            "model_state_dict": self.model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": scheduler.state_dict(),
            "best_loss": self.best_loss,
            "training_history": self.training_history,
            "config": {
                "t5_config": T5_CONFIG.dict(),
                "training_config": TRAINING_CONFIG.dict()
            }
        }
        
        torch.save(checkpoint, checkpoint_path)
        logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    
    def save_model(self, save_dir: str, is_best: bool = False):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
            is_best: æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        """
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹æƒé‡
        model_path = os.path.join(save_dir, "pytorch_model.bin")
        torch.save(self.model.state_dict(), model_path)
        
        # ä¿å­˜é…ç½®
        config_path = os.path.join(save_dir, "config.json")
        config_dict = {
            "t5_config": T5_CONFIG.dict(),
            "training_config": TRAINING_CONFIG.dict(),
            "training_info": {
                "epoch": self.current_epoch,
                "global_step": self.global_step,
                "best_loss": self.best_loss,
                "is_best": is_best
            }
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(save_dir, "training_history.json")
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_dir}")
    
    def train(self) -> List[Dict[str, float]]:
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        
        Returns:
            training_history: è®­ç»ƒå†å²
        """
        logger.info("å¼€å§‹T5è®­ç»ƒ...")
        
        # è®¾ç½®æ•°æ®åŠ è½½å™¨
        train_loader, val_loader = self.setup_data_loaders()
        
        # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer, scheduler = self.setup_optimizer_and_scheduler(train_loader)
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(TRAINING_CONFIG.num_epochs):
            self.current_epoch = epoch
            
            logger.info(f"\n{'='*50}")
            logger.info(f"Epoch {epoch + 1}/{TRAINING_CONFIG.num_epochs}")
            logger.info(f"{'='*50}")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self.train_epoch(train_loader, optimizer, scheduler)
            
            # éªŒè¯
            val_metrics = self.validate(val_loader)
            
            # åˆå¹¶æŒ‡æ ‡
            epoch_metrics = {**train_metrics, **val_metrics}
            epoch_metrics["epoch"] = epoch + 1
            epoch_metrics["timestamp"] = datetime.now().isoformat()
            
            # è®°å½•è®­ç»ƒå†å²
            self.training_history.append(epoch_metrics)
            
            # æ—¥å¿—è®°å½•
            logger.info(f"Epoch {epoch + 1} å®Œæˆ:")
            logger.info(f"  è®­ç»ƒæŸå¤±: {train_metrics['train_loss']:.4f}")
            logger.info(f"  éªŒè¯æŸå¤±: {val_metrics['val_loss']:.4f}")
            logger.info(f"  å­¦ä¹ ç‡: {train_metrics['learning_rate']:.2e}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['val_loss'] < self.best_loss:
                self.best_loss = val_metrics['val_loss']
                self.save_model(self.best_model_dir, is_best=True)
                logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±: {self.best_loss:.4f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(optimizer, scheduler)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_model(self.final_model_dir, is_best=False)
        
        logger.info("è®­ç»ƒå®Œæˆ!")
        logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_loss:.4f}")
        
        return self.training_history


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒå™¨
    from config import setup_logging
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = T5Trainer()
    
    # å¼€å§‹è®­ç»ƒ
    history = trainer.train()
    
    logger.info("è®­ç»ƒå™¨æµ‹è¯•å®Œæˆ!")
