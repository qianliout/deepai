"""
T5æ¡†æ¶ç»„ä»¶æµ‹è¯•è„šæœ¬
æµ‹è¯•å„ä¸ªæ¨¡å—çš„åŸºæœ¬åŠŸèƒ½
"""

import torch
import logging
from config import setup_logging, T5_CONFIG, print_config
from transformer import LayerNorm, MultiHeadAttention, FeedForward
from model import T5Model, T5ForConditionalGeneration
from data_loader import T5DataSample

logger = logging.getLogger("T5")


def test_config():
    """æµ‹è¯•é…ç½®æ¨¡å—"""
    print("\nğŸ”§ æµ‹è¯•é…ç½®æ¨¡å—")
    print("-" * 30)
    
    print(f"æ¨¡å‹ç»´åº¦: {T5_CONFIG.d_model}")
    print(f"å±‚æ•°: {T5_CONFIG.num_layers}")
    print(f"æ³¨æ„åŠ›å¤´æ•°: {T5_CONFIG.num_heads}")
    print(f"è¯æ±‡è¡¨å¤§å°: {T5_CONFIG.vocab_size}")
    
    print("âœ… é…ç½®æ¨¡å—æµ‹è¯•é€šè¿‡")


def test_transformer_components():
    """æµ‹è¯•Transformerç»„ä»¶"""
    print("\nğŸ”§ æµ‹è¯•Transformerç»„ä»¶")
    print("-" * 30)
    
    batch_size, seq_len, d_model = 2, 10, T5_CONFIG.d_model
    
    # æµ‹è¯•LayerNorm
    print("æµ‹è¯•LayerNorm...")
    layer_norm = LayerNorm(d_model)
    x = torch.randn(batch_size, seq_len, d_model)
    output = layer_norm(x)
    assert output.shape == (batch_size, seq_len, d_model)
    print(f"  è¾“å…¥shape: {x.shape}")
    print(f"  è¾“å‡ºshape: {output.shape}")
    
    # æµ‹è¯•MultiHeadAttention
    print("æµ‹è¯•MultiHeadAttention...")
    attention = MultiHeadAttention(has_relative_attention_bias=True)
    hidden_states = torch.randn(batch_size, seq_len, d_model)
    attn_output, position_bias, _ = attention(hidden_states)
    assert attn_output.shape == (batch_size, seq_len, d_model)
    print(f"  è¾“å…¥shape: {hidden_states.shape}")
    print(f"  è¾“å‡ºshape: {attn_output.shape}")
    print(f"  ä½ç½®åç½®shape: {position_bias.shape}")
    
    # æµ‹è¯•FeedForward
    print("æµ‹è¯•FeedForward...")
    ff = FeedForward()
    ff_output = ff(hidden_states)
    assert ff_output.shape == (batch_size, seq_len, d_model)
    print(f"  è¾“å…¥shape: {hidden_states.shape}")
    print(f"  è¾“å‡ºshape: {ff_output.shape}")
    
    print("âœ… Transformerç»„ä»¶æµ‹è¯•é€šè¿‡")


def test_model():
    """æµ‹è¯•æ¨¡å‹"""
    print("\nğŸ”§ æµ‹è¯•æ¨¡å‹")
    print("-" * 30)
    
    batch_size = 2
    encoder_seq_len = 10
    decoder_seq_len = 8
    
    # æµ‹è¯•T5Model
    print("æµ‹è¯•T5Model...")
    model = T5Model()
    
    # å‡†å¤‡è¾“å…¥
    input_ids = torch.randint(0, T5_CONFIG.vocab_size, (batch_size, encoder_seq_len))
    decoder_input_ids = torch.randint(0, T5_CONFIG.vocab_size, (batch_size, decoder_seq_len))
    
    outputs = model(
        input_ids=input_ids,
        decoder_input_ids=decoder_input_ids
    )
    
    print(f"  ç¼–ç å™¨è¾“å…¥shape: {input_ids.shape}")
    print(f"  è§£ç å™¨è¾“å…¥shape: {decoder_input_ids.shape}")
    print(f"  è§£ç å™¨è¾“å‡ºshape: {outputs['last_hidden_state'].shape}")
    print(f"  ç¼–ç å™¨è¾“å‡ºshape: {outputs['encoder_last_hidden_state'].shape}")
    
    # æµ‹è¯•T5ForConditionalGeneration
    print("æµ‹è¯•T5ForConditionalGeneration...")
    model_gen = T5ForConditionalGeneration()
    
    labels = torch.randint(0, T5_CONFIG.vocab_size, (batch_size, decoder_seq_len))
    
    outputs = model_gen(
        input_ids=input_ids,
        decoder_input_ids=decoder_input_ids,
        labels=labels
    )
    
    print(f"  logits shape: {outputs['logits'].shape}")
    print(f"  loss: {outputs['loss'].item():.4f}")
    
    print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡")


def test_data_sample():
    """æµ‹è¯•æ•°æ®æ ·æœ¬"""
    print("\nğŸ”§ æµ‹è¯•æ•°æ®æ ·æœ¬")
    print("-" * 30)
    
    # åˆ›å»ºæµ‹è¯•æ ·æœ¬
    sample = T5DataSample(
        input_ids=[1, 2, 3, 4, 5],
        attention_mask=[1, 1, 1, 1, 1],
        decoder_input_ids=[0, 1, 2, 3],
        decoder_attention_mask=[1, 1, 1, 1],
        labels=[1, 2, 3, -100]
    )
    
    print(f"  input_ids: {sample.input_ids}")
    print(f"  attention_mask: {sample.attention_mask}")
    print(f"  decoder_input_ids: {sample.decoder_input_ids}")
    print(f"  labels: {sample.labels}")
    
    print("âœ… æ•°æ®æ ·æœ¬æµ‹è¯•é€šè¿‡")


def test_parameter_count():
    """æµ‹è¯•å‚æ•°æ•°é‡"""
    print("\nğŸ”§ æµ‹è¯•å‚æ•°æ•°é‡")
    print("-" * 30)
    
    model = T5ForConditionalGeneration()
    param_count = model.count_parameters()
    
    print(f"  æ€»å‚æ•°æ•°é‡: {param_count:,}")
    
    # è®¡ç®—ç†è®ºå‚æ•°æ•°é‡ï¼ˆå¤§è‡´ä¼°ç®—ï¼‰
    d_model = T5_CONFIG.d_model
    vocab_size = T5_CONFIG.vocab_size
    num_layers = T5_CONFIG.num_layers
    d_ff = T5_CONFIG.d_ff
    
    # åµŒå…¥å±‚å‚æ•°
    embedding_params = vocab_size * d_model
    
    # æ¯å±‚çš„å‚æ•°ï¼ˆæ³¨æ„åŠ› + å‰é¦ˆï¼‰
    attention_params_per_layer = 4 * d_model * d_model  # q, k, v, o
    ff_params_per_layer = 2 * d_model * d_ff  # wi, wo
    layer_params = (attention_params_per_layer + ff_params_per_layer) * 2  # ç¼–ç å™¨ + è§£ç å™¨
    
    # æ€»å‚æ•°ä¼°ç®—
    estimated_params = embedding_params + layer_params * num_layers
    
    print(f"  ä¼°ç®—å‚æ•°æ•°é‡: {estimated_params:,}")
    print(f"  å‚æ•°æ•°é‡åˆç†æ€§: {'âœ…' if abs(param_count - estimated_params) / estimated_params < 0.5 else 'âŒ'}")
    
    print("âœ… å‚æ•°æ•°é‡æµ‹è¯•é€šè¿‡")


def test_device_compatibility():
    """æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§"""
    print("\nğŸ”§ æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§")
    print("-" * 30)
    
    from config import get_device
    
    device = get_device()
    print(f"  æ£€æµ‹åˆ°çš„è®¾å¤‡: {device}")
    
    # æµ‹è¯•æ¨¡å‹åœ¨è®¾å¤‡ä¸Šçš„è¿è¡Œ
    model = T5ForConditionalGeneration()
    model.to(device)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    seq_len = 5
    input_ids = torch.randint(0, 100, (batch_size, seq_len)).to(device)
    decoder_input_ids = torch.randint(0, 100, (batch_size, seq_len)).to(device)
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)
    
    print(f"  æ¨¡å‹è¾“å‡ºè®¾å¤‡: {outputs['logits'].device}")
    print(f"  è®¾å¤‡å…¼å®¹æ€§: {'âœ…' if outputs['logits'].device == device else 'âŒ'}")
    
    print("âœ… è®¾å¤‡å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    print("ğŸš€ å¼€å§‹T5æ¡†æ¶ç»„ä»¶æµ‹è¯•")
    print("=" * 50)
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_config()
        test_transformer_components()
        test_model()
        test_data_sample()
        test_parameter_count()
        test_device_compatibility()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 50)
        print("T5æ¡†æ¶å„ç»„ä»¶å·¥ä½œæ­£å¸¸")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
