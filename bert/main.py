"""
ä¸»è¿è¡Œè„šæœ¬ - BERTæ¡†æ¶çš„ç»Ÿä¸€å…¥å£
æ”¯æŒé¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ç­‰æ‰€æœ‰åŠŸèƒ½
ä¸éœ€è¦æ‰‹åŠ¨ä¼ å‚ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨config.pyä¸­é…ç½®
"""

import argparse
import logging
import sys
from pathlib import Path

from config import print_config, setup_logging, DataConfig, TRAINING_CONFIG
from trainer import BertTrainer
from fine_tuning import BertFineTuner
from inference import BertInference

logger = logging.getLogger("BERT")


def run_pretraining():
    """è¿è¡Œé¢„è®­ç»ƒ"""
    print("\nğŸš€ å¼€å§‹BERTé¢„è®­ç»ƒ")
    print("=" * 50)

    # æ‰“å°é…ç½®ä¿¡æ¯
    print_config()

    # åˆ›å»ºå¹¶è¿è¡Œè®­ç»ƒå™¨
    trainer = BertTrainer()
    history = trainer.train()

    print("\nğŸ‰ é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æŸå¤±: {trainer.best_loss:.4f}")
    print(f"è¾“å‡ºç›®å½•: {trainer.output_dir}")
    print(f"æœ€ä½³æ¨¡å‹: {trainer.output_dir}/best_model")

    return history


def run_fine_tuning(pretrained_model_path: str = None):
    """è¿è¡Œå¾®è°ƒ"""
    print("\nğŸ”§ å¼€å§‹BERTå¾®è°ƒ")
    print("=" * 50)

    # å¦‚æœæ²¡æœ‰æŒ‡å®šé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if pretrained_model_path is None:
        pretrained_model_path = TRAINING_CONFIG.output_dir + "/" + "best_model"

    pretrained_path = Path(pretrained_model_path)
    if not pretrained_path.exists():
        print(f"âŒ é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {pretrained_path}")
        print("è¯·å…ˆè¿è¡Œé¢„è®­ç»ƒæˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        return None

    print(f"ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {pretrained_path}")

    # åˆ›å»ºå¹¶è¿è¡Œå¾®è°ƒå™¨
    fine_tuner = BertFineTuner(pretrained_model_path, num_labels=2)
    history = fine_tuner.fine_tune()

    print("\nğŸ‰ å¾®è°ƒå®Œæˆï¼")
    print(f"æœ€ä½³å‡†ç¡®ç‡: {fine_tuner.best_accuracy:.4f}")
    print(f"è¾“å‡ºç›®å½•: {fine_tuner.output_dir}")
    print(f"æœ€ä½³æ¨¡å‹: {fine_tuner.output_dir}/best_model")

    return history


def run_inference(model_path: str = None, model_type: str = "pretraining"):
    """è¿è¡Œæ¨ç†"""
    print("\nğŸ” å¼€å§‹BERTæ¨ç†")
    print("=" * 50)

    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤è·¯å¾„
    if model_path is None:
        if model_type == "pretraining":
            model_path = os.path.join(TRAINING_CONFIG.model_save_dir, "best_model")
        else:
            model_path = os.path.join(TRAINING_CONFIG.fine_tuning_save_dir, "best_model")

    model_path_obj = Path(model_path)
    if not model_path_obj.exists():
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path_obj}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒæˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        return

    print(f"ä½¿ç”¨æ¨¡å‹: {model_path_obj}")
    print(f"æ¨¡å‹ç±»å‹: {model_type}")

    # åˆ›å»ºæ¨ç†å™¨
    inference = BertInference(model_path, model_type)

    # äº¤äº’å¼æ¨ç†
    print("\nå¼€å§‹äº¤äº’å¼æ¨ç†...")
    print("è¾“å…¥ 'quit' é€€å‡º")

    while True:
        try:
            if model_type == "pretraining":
                print("\n--- æ©ç è¯­è¨€æ¨¡å‹é¢„æµ‹ ---")
                text = input("è¯·è¾“å…¥åŒ…å«[MASK]çš„æ–‡æœ¬: ")
                if text.lower() == "quit":
                    break

                results = inference.predict_masked_tokens(text, top_k=3)
                if results:
                    for result in results:
                        print(f"\nä½ç½® {result['position']} çš„é¢„æµ‹:")
                        for i, pred in enumerate(result["predictions"], 1):
                            print(f"  {i}. {pred['token']}: {pred['probability']:.4f}")
                else:
                    print("æ²¡æœ‰æ‰¾åˆ°[MASK] token")

            elif model_type == "classification":
                print("\n--- æ–‡æœ¬åˆ†ç±»é¢„æµ‹ ---")
                text = input("è¯·è¾“å…¥è¦åˆ†ç±»çš„æ–‡æœ¬: ")
                if text.lower() == "quit":
                    break

                result = inference.classify_text(text)
                print(f"\né¢„æµ‹ç»“æœ:")
                print(f"  ç±»åˆ«: {result['predicted_class']}")
                print(f"  ç½®ä¿¡åº¦: {result['confidence']:.4f}")

                # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
                print(f"  æ‰€æœ‰æ¦‚ç‡:")
                for i, prob in enumerate(result["all_probabilities"]):
                    print(f"    ç±»åˆ« {i}: {prob:.4f}")

        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

    print("\næ¨ç†å™¨å·²é€€å‡º")


def run_full_pipeline():
    """è¿è¡Œå®Œæ•´æµç¨‹ï¼šé¢„è®­ç»ƒ + å¾®è°ƒ"""
    print("\nğŸ”„ å¼€å§‹å®Œæ•´BERTæµç¨‹")
    print("=" * 50)

    # 1. é¢„è®­ç»ƒ
    print("\nç¬¬ä¸€æ­¥ï¼šé¢„è®­ç»ƒ")
    pretrain_history = run_pretraining()

    if pretrain_history is None:
        print("âŒ é¢„è®­ç»ƒå¤±è´¥ï¼Œåœæ­¢æµç¨‹")
        return

    # 2. å¾®è°ƒ
    print("\nç¬¬äºŒæ­¥ï¼šå¾®è°ƒ")
    finetune_history = run_fine_tuning()

    if finetune_history is None:
        print("âŒ å¾®è°ƒå¤±è´¥")
        return

    print("\nğŸ‰ å®Œæ•´æµç¨‹å®Œæˆï¼")
    print("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†ï¼š")
    print("  é¢„è®­ç»ƒæ¨¡å‹æ¨ç†: python main.py inference --model_type pretraining")
    print("  åˆ†ç±»æ¨¡å‹æ¨ç†: python main.py inference --model_type classification")


def run_quick_test():
    """å¿«é€Ÿæµ‹è¯• - ä½¿ç”¨å°è§„æ¨¡é…ç½®"""
    print("\nâš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("=" * 50)

    # ä¸´æ—¶ä¿®æ”¹é…ç½®ä¸ºå°è§„æ¨¡
    from config import BERT_CONFIG, TRAINING_CONFIG

    # ä¿å­˜åŸå§‹é…ç½®
    original_config = {
        "hidden_size": BERT_CONFIG.hidden_size,
        "num_hidden_layers": BERT_CONFIG.num_hidden_layers,
        "num_attention_heads": BERT_CONFIG.num_attention_heads,
        "intermediate_size": BERT_CONFIG.intermediate_size,
        "num_epochs": TRAINING_CONFIG.num_epochs,
        "max_samples": TRAINING_CONFIG.max_samples,
        "batch_size": TRAINING_CONFIG.batch_size,
    }

    # è®¾ç½®å°è§„æ¨¡é…ç½®
    BERT_CONFIG.hidden_size = 256
    BERT_CONFIG.num_hidden_layers = 4
    BERT_CONFIG.num_attention_heads = 4
    BERT_CONFIG.intermediate_size = 1024
    TRAINING_CONFIG.num_epochs = 1
    TRAINING_CONFIG.max_samples = 100
    TRAINING_CONFIG.batch_size = 8
    # æ›´æ–°å¿«é€Ÿæµ‹è¯•çš„ä¿å­˜ç›®å½•
    TRAINING_CONFIG.model_save_dir = "/Users/liuqianli/work/python/deepai/saved_model/bert_quick_test"
    TRAINING_CONFIG.fine_tuning_save_dir = "/Users/liuqianli/work/python/deepai/saved_model/bert_quick_test/fine_tuning"
    TRAINING_CONFIG.log_dir = "/Users/liuqianli/work/python/deepai/logs/bert_quick_test"

    print("ä½¿ç”¨å°è§„æ¨¡é…ç½®è¿›è¡Œå¿«é€Ÿæµ‹è¯•...")

    try:
        # è¿è¡Œé¢„è®­ç»ƒ
        pretrain_history = run_pretraining()

        if pretrain_history:
            # è¿è¡Œå¾®è°ƒ
            run_fine_tuning()

        print("\nâš¡ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")

    finally:
        # æ¢å¤åŸå§‹é…ç½®
        for key, value in original_config.items():
            if hasattr(BERT_CONFIG, key):
                setattr(BERT_CONFIG, key, value)
            elif hasattr(TRAINING_CONFIG, key):
                setattr(TRAINING_CONFIG, key, value)


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    setup_logging()

    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(
        description="BERTæ¡†æ¶ - ç»Ÿä¸€å…¥å£",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py pretrain                    # é¢„è®­ç»ƒ
  python main.py finetune                    # å¾®è°ƒï¼ˆä½¿ç”¨é»˜è®¤é¢„è®­ç»ƒæ¨¡å‹ï¼‰
  python main.py inference                   # æ¨ç†ï¼ˆé¢„è®­ç»ƒæ¨¡å‹ï¼‰
  python main.py inference --model_type classification  # æ¨ç†ï¼ˆåˆ†ç±»æ¨¡å‹ï¼‰
  python main.py full                        # å®Œæ•´æµç¨‹
  python main.py quick                       # å¿«é€Ÿæµ‹è¯•

æ³¨æ„ï¼šæ‰€æœ‰å‚æ•°éƒ½åœ¨config.pyä¸­é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨ä¼ å‚
        """,
    )

    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # é¢„è®­ç»ƒå‘½ä»¤
    pretrain_parser = subparsers.add_parser("pretrain", help="è¿è¡Œé¢„è®­ç»ƒ")

    # å¾®è°ƒå‘½ä»¤
    finetune_parser = subparsers.add_parser("finetune", help="è¿è¡Œå¾®è°ƒ")
    finetune_parser.add_argument(
        "--pretrained_model_path",
        type=str,
        help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤: ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰",
    )

    # æ¨ç†å‘½ä»¤
    inference_parser = subparsers.add_parser("inference", help="è¿è¡Œæ¨ç†")
    inference_parser.add_argument("--model_path", type=str, help="æ¨¡å‹è·¯å¾„")
    inference_parser.add_argument(
        "--model_type",
        type=str,
        choices=["pretraining", "classification"],
        default="pretraining",
        help="æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: pretrainingï¼‰",
    )

    # å®Œæ•´æµç¨‹å‘½ä»¤
    full_parser = subparsers.add_parser("full", help="è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆé¢„è®­ç»ƒ+å¾®è°ƒï¼‰")

    # å¿«é€Ÿæµ‹è¯•å‘½ä»¤
    quick_parser = subparsers.add_parser("quick", help="å¿«é€Ÿæµ‹è¯•ï¼ˆå°è§„æ¨¡é…ç½®ï¼‰")

    # è§£æå‚æ•°
    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æä¾›å‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if args.command is None:
        parser.print_help()
        return

    try:
        # æ‰§è¡Œå¯¹åº”çš„å‘½ä»¤
        if args.command == "pretrain":
            run_pretraining()

        elif args.command == "finetune":
            run_fine_tuning(args.pretrained_model_path)

        elif args.command == "inference":
            run_inference(args.model_path, args.model_type)

        elif args.command == "full":
            run_full_pipeline()

        elif args.command == "quick":
            run_quick_test()

        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {args.command}")
            parser.print_help()

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
