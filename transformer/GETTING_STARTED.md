# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ ä¸€é”®è¿è¡Œ

### æ–¹æ³•1: ä½¿ç”¨ä¸€é”®è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
cd transformer/auge
python run.py
```

### æ–¹æ³•2: ç›´æ¥è¿è¡Œä¸»ç¨‹åº
```bash
cd transformer/auge
python main.py --mode train
```

## ğŸ“‹ è¿è¡Œå‰æ£€æŸ¥

### 1. éªŒè¯ç¯å¢ƒè®¾ç½®
```bash
python test_setup.py
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

## ğŸ¯ å¿«é€Ÿè®­ç»ƒæµç¨‹

### æ­¥éª¤1: è®­ç»ƒæ¨¡å‹
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python main.py --mode train

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python main.py --mode train --config example_config.json
```

### æ­¥éª¤2: æµ‹è¯•æ¨¡å‹
```bash
# è‡ªåŠ¨æ‰¾åˆ°æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
python main.py --mode test --model_path ./saved_models/best_model_epoch_X.pt
```

### æ­¥éª¤3: äº¤äº’å¼ç¿»è¯‘
```bash
python inference.py --model_path ./saved_models/best_model_epoch_X.pt --mode interactive
```

## ğŸ“Š è®­ç»ƒé…ç½®è¯´æ˜

### å¿«é€Ÿè®­ç»ƒï¼ˆæµ‹è¯•ç”¨ï¼‰
- è®­ç»ƒæ•°æ®: 1000æ¡
- éªŒè¯æ•°æ®: 200æ¡  
- æ¨¡å‹ç»´åº¦: 128
- è®­ç»ƒè½®æ•°: 3è½®
- é¢„è®¡æ—¶é—´: 10-20åˆ†é’Ÿ

### æ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰
- è®­ç»ƒæ•°æ®: 10000æ¡
- éªŒè¯æ•°æ®: 2000æ¡
- æ¨¡å‹ç»´åº¦: 512
- è®­ç»ƒè½®æ•°: 10è½®
- é¢„è®¡æ—¶é—´: 2-4å°æ—¶

### é«˜è´¨é‡è®­ç»ƒ
- è®­ç»ƒæ•°æ®: 50000æ¡
- éªŒè¯æ•°æ®: 10000æ¡
- æ¨¡å‹ç»´åº¦: 768
- è®­ç»ƒè½®æ•°: 20è½®
- é¢„è®¡æ—¶é—´: 8-12å°æ—¶

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### åˆ›å»ºé…ç½®æ–‡ä»¶
```python
from config import Config

# ä¿®æ”¹é…ç½®
config = Config()
config.model.d_model = 256
config.training.batch_size = 16
config.training.num_epochs = 5

# ä¿å­˜é…ç½®
config.save_config("my_config.json")
```

### ä½¿ç”¨é…ç½®æ–‡ä»¶
```bash
python main.py --mode train --config my_config.json
```

## ğŸ“± ä½¿ç”¨ç¤ºä¾‹

### 1. ä¸€é”®è®­ç»ƒå’Œæµ‹è¯•
```bash
python run.py --action train
```

### 2. å¿«é€Ÿç¿»è¯‘
```bash
python run.py --action translate --text "Hello, how are you?"
```

### 3. äº¤äº’å¼ç¿»è¯‘
```bash
python run.py --action interactive
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: å‡å°batch_sizeæˆ–æ¨¡å‹ç»´åº¦
```json
{
  "training": {
    "batch_size": 8
  },
  "model": {
    "d_model": 256
  }
}
```

### Q: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢ï¼Ÿ
A: æ£€æŸ¥æ˜¯å¦ä½¿ç”¨GPU
```python
import torch
print(torch.backends.mps.is_available())  # Mac M1/M2
print(torch.cuda.is_available())          # NVIDIA GPU
```

### Q: æ•°æ®ä¸‹è½½å¤±è´¥ï¼Ÿ
A: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨ä»£ç†
```bash
export HF_ENDPOINT=https://hf-mirror.com
python main.py --mode train
```

### Q: ç¿»è¯‘è´¨é‡ä¸å¥½ï¼Ÿ
A: å¢åŠ è®­ç»ƒæ•°æ®å’Œè®­ç»ƒè½®æ•°
```json
{
  "training": {
    "train_size": 50000,
    "num_epochs": 20
  }
}
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### æŸ¥çœ‹æ—¥å¿—
```bash
tail -f logs/training_*.log
```

### è®­ç»ƒæŒ‡æ ‡
- Loss: æŸå¤±å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- Perplexity: å›°æƒ‘åº¦ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- Learning Rate: å­¦ä¹ ç‡å˜åŒ–

### ä¿å­˜çš„æ–‡ä»¶
- `saved_models/`: æ¨¡å‹æ£€æŸ¥ç‚¹
- `vocab/`: è¯å…¸æ–‡ä»¶
- `logs/`: è®­ç»ƒæ—¥å¿—
- `data_cache/`: æ•°æ®ç¼“å­˜

## ğŸ‰ æˆåŠŸæ ‡å¿—

è®­ç»ƒæˆåŠŸåï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š
1. âœ… æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨ `saved_models/`
2. âœ… è¯å…¸æ–‡ä»¶ä¿å­˜åœ¨ `vocab/`
3. âœ… éªŒè¯æŸå¤±é€æ¸ä¸‹é™
4. âœ… ç®€å•ç¿»è¯‘æµ‹è¯•æœ‰åˆç†è¾“å‡º

## ğŸ”„ ä¸‹ä¸€æ­¥

1. **æå‡ç¿»è¯‘è´¨é‡**: å¢åŠ è®­ç»ƒæ•°æ®å’Œè½®æ•°
2. **æ·»åŠ æ–°åŠŸèƒ½**: å®ç°Beam Searchè§£ç 
3. **è¯„ä¼°æ¨¡å‹**: è®¡ç®—BLEUåˆ†æ•°
4. **å¯è§†åŒ–**: æ·»åŠ æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–
5. **æ‰©å±•è¯­è¨€**: æ”¯æŒæ›´å¤šè¯­è¨€å¯¹

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. è¿è¡Œ `python test_setup.py` æ£€æŸ¥ç¯å¢ƒ
2. æŸ¥çœ‹ `logs/` ç›®å½•ä¸‹çš„è¯¦ç»†æ—¥å¿—
3. æ£€æŸ¥ `README.md` ä¸­çš„è¯¦ç»†è¯´æ˜
4. ç¡®ä¿æ‰€æœ‰ä¾èµ–æ­£ç¡®å®‰è£…

ç¥ä½ è®­ç»ƒæ„‰å¿«ï¼ğŸš€
